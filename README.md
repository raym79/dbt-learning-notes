# 1. Analytics Development Lifecycle

## 1.1 ELT vs ETL

## 1.2 Data team roles
- DE - Data engineers build systems to collect and process data. They create the foundation for all data work. Their expertise centers on building reliable pipelines.
    - Designing data infrastructure and architecture
    - Creating and maintaining data pipelines
    - Ensuring data quality and availability  

- AE - Analytics engineering is a relatively recent data team role. Since then, the field has grown across industries. An analytics engineer is a valuable addition to a data team. 
    - Exploration: Exploring data already ingested into data platforms in response to stakeholder questions and needs.
    - Preparation: Cleaning and preparing datasets for analytics use cases.
    - Transformation: Transforming prepared datasets into objects that can serve organizational objectives, such as a super-table that can serve as a base for multiple applications.
    - Documentation: Documenting the objects they find and create in the data warehouse, ensuring that other users can also see, understand, and use them.

- DA
    - Interpreting data to find trends
    - Creating reports and visualizations
    - Working closely with business stakeholders

## 1.3 Analytics Development Life Cycle (ADLC)
![ADLC](https://www.getdbt.com/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fwl0ndo6t%2Fmain%2F6a2eca8c4be8bc95297a2c67c14b3a4aa8e862a4-1850x906.png%3Ffit%3Dmax%26auto%3Dformat&w=1920&q=75)

## 1.4 dbt project structure
Typical dbt project:  
```
my_dbt_project/
│
├── dbt_project.yml
├── models/
├── seeds/
├── macros/
├── snapshots/
├── tests/
└── target/   (generated by dbt)
```
### 1.4.1 dbt_project.yml (main config file)
This is the central configuration file.
It defines:
- Project name
- Model materializations
- Folder-level settings
- Database/schema behavior
Think of it as the control center of the project.

### 1.4.2 models (most important folder)
This is where all SQL transformations live.
- Each .sql file = one model
- Each model becomes a table or view
```
models/
  staging/
  core/
```
Models transform raw data into analytics tables.

#### Layered modeling approach
The lecture introduces layered data modeling.  
Layer 1: Staging
Purpose:
- Clean raw data
- Rename columns
- Cast data types
- Minimal logic
Example:
```
stg_orders.sql
Usually materialized as views.
```

#### Layer 2: Core / Marts

Purpose:
- Business logic
- Fact and dimension tables
- Final analytics datasets
Examples:
```
fact_orders.sql
dim_customers.sql
```
Usually materialized as tables or incremental models.

### 1.4.3 seeds
- A space to upload csv and flat files (to add them to dbt later)
- Loaded into the warehouse as tables
- Used for small static datasets
- Quick and dirty approach (better to fix at source)

### 1.4.4 macros
- They behave like Python functions (reusable logic)
- They help you encapsulate logic (in one place)

### 1.4.5 snapshots
- Track changes in records over time
- Used for slowly changing dimensions (SCD)

### 1.4.6 tests
- Data quality tests
- Example:
    - not null
    - unique
    - relationships

### 1.4.7 target
- Auto-generated by dbt
- Contains compiled SQL and run artifacts
- Not edited manually

### 1.4.8 analyses
- A place for SQL files that you don't want to expose
- Can generally use it for data quality reports
- Not everyone use it though

### 1.4.9 README.md
- The documentation of your project
- Installation/setup guides

### 1.4.10 ref() function
Used to reference another model:
```
SELECT * FROM {{ ref('stg_orders') }}
```

Benefits: 
- Creates dependency graph
- Ensures correct build order
- Enables lineage tracking




# 2. dbt Models
In dbt, models are just SQL select statemnet that we use to shape our data. 

## 2.1 Structure
dbt projects are structured to move data through layers:  
```
Sources (raw tables)
        ↓
Staging models (cleaned data)
        ↓
Core/Mart models (business logic)
        ↓
Analytics-ready tables
```
## 2.2 Layer-based naming
`Sources → Staging → Intermediate → Marts`
```
models/
  staging/
  intermediate/
  marts/
```
- Staging models  
`stg_`
- Intermediate models  
`int_`
- Mart models (final business tables)
    - Fact tables
        - `fct_`
    - Dimension tables
        - `dim_`

# 3. dbt macros
Need to learn more about programming for macros  

# 4. dbt Tests
## 4.1 Two main types of tests in dbt
### 1) Generic tests (built-in tests)

These are predefined tests provided by dbt.
You define them in YAML files.
Common built-in tests:
|       Test      |       What it checks       |
|:---------------:|:--------------------------:|
| not_null        | No NULL values in a column |
| unique          | No duplicate values        |
| accepted_values | Only allowed values exist  |
| relationships   | Foreign key integrity      |

Example: generic test in YAML
```
version: 2

models:
  - name: stg_orders
    columns:
      - name: order_id
        tests:
          - not_null
          - unique
```
### 2) Singular tests (custom tests)
These are custom SQL queries written by you.
- Stored as .sql files
- Located in the tests/ directory

Example:
```
tests/
  test_positive_amount.sql
```

Example SQL test:
```
SELECT *
FROM {{ ref('stg_orders') }}
WHERE order_amount < 0
```

If this query returns rows -> The test fails

## 4.2 Where tests are stored
- Typical structure:
```
models/
  staging/
    schema.yml

tests/
  test_positive_amount.sql
```
- How to run tests

Command:
```
dbt test
```

- What happens:
    - dbt runs all defined tests.
    - If a test query returns rows → test fails.
    - Results appear in logs or dbt Cloud.

## 4.3 Testing sources

You can also test sources, not just models.

Example:
```
sources:
  - name: raw_data
    tables:
      - name: orders
        columns:
          - name: order_id
            tests:
              - not_null
              - unique
```

This ensures raw data quality before transformations.

Typical testing flow
```
Source tables
   ↓ (source tests)
Staging models
   ↓ (model tests)
Intermediate models
   ↓
Mart models
```

**Tests can exist at any layer.**

# 5. dbt Documentation

## 5.1 What is dbt documentation?

dbt documentation:
- Describes models, sources, and columns
- Lives inside YAML files in the project
- Can be turned into a web-based data catalog

It helps:
- Analysts understand tables
- Teams trust the data
- New members onboard faster


## 5.2 Where documentation is written

Documentation is defined in YAML files inside the models/ directory.

Example:
```
models/
  staging/
    schema.yml
```
Basic documentation structure

Example YAML with documentation:
```
version: 2

models:
  - name: stg_orders
    description: Cleaned orders data from raw source
    columns:
      - name: order_id
        description: Unique identifier for each order
      - name: customer_id
        description: ID of the customer who placed the order
```

This documents:
- The model
- Each column

## 5.3 Generating dbt documentation

dbt provides built-in commands to create and view docs.

**Step 1**: Generate documentation  
`dbt docs generate`

What this does:
- Reads all models, sources, tests, and descriptions
- Builds documentation files

**Step 2**: Serve documentation locally
`dbt docs serve`
This:
- Starts a local web server
- Opens a browser with the dbt docs site

## 5.4 What you see in dbt docs

The dbt documentation site includes:

1) Data catalog
    - List of models
    - Column descriptions
    - Tests
2) Lineage graph (DAG)
A visual graph showing:
`Sources → Staging → Intermediate → Marts`

This helps users:
- Understand dependencies
- Trace where data comes from

# 6. dbt Packages

## 6.1 What is a dbt package?

A dbt package is:
- A collection of prebuilt dbt models, macros, or tests
- Created by the dbt community or your team
- Installed into your project

Think of packages like:
- Libraries in Python
- npm packages in JavaScript

They help you:
- Avoid reinventing common logic
- Standardize transformations
- Speed up development

## 6.2 Where packages are defined

Packages are defined in a file called:
`packages.yml`

This file lives in the root of the dbt project.

Example: installing a package

Example `packages.yml`:
```
packages:
  - package: dbt-labs/dbt_utils
    version: 1.1.1
```

This installs the dbt_utils package.

## 6.3 Installing packages

After adding packages.yml, run:
`dbt deps`

What this does:
- Downloads the packages
- Stores them in the dbt_packages/ folder
- Makes them available to your project

Note: [dbt Hub](https://hub.getdbt.com/dbt-labs/dbt_project_evaluator/latest/)


# 7. dbt Commands

## 7.1 dbt run
Purpose: Build models.
`dbt run`

What it does:
- Executes all models in the project
- Creates tables or views in the warehouse
- Builds models in the correct dependency order

## 7.2 dbt test
Purpose: Run data quality tests.
`dbt test`

What it does:
- Executes all defined tests
- Reports failures if tests return rows

## 7.3 dbt build
Purpose: Run the entire pipeline.  
`dbt build`

What it does:
- Runs models
- Runs tests
- Processes seeds
- Runs snapshots
 
It is a full pipeline command.

**Key difference: run vs build**  
|  Command  |                What it does               |
|:---------:|:-----------------------------------------:|
| dbt run   | Builds models only                        |
| dbt build | Builds models + tests + seeds + snapshots |

## 7.4 dbt seed
Purpose: Load CSV files into the warehouse.
`dbt seed`
What it does:
- Reads CSV files from the seeds/ folder
- Loads them as tables

## 7.5 dbt snapshot
Purpose: Run snapshot logic.
`dbt snapshot`

What it does:
- Tracks historical changes in data
- Used for slowly changing dimensions

## 7.6 dbt deps
Purpose: Install packages.
`dbt deps`

What it does:
- Downloads packages defined in packages.yml
- Stores them in dbt_packages/

## 7.7 dbt docs generate
Purpose: Generate project documentation.
`dbt docs generate`

What it does:
- Builds the documentation site
- Creates lineage graphs and metadata

## 7.8 dbt docs serve
Purpose: View documentation locally.
`dbt docs serve`
What it does:
- Starts a local web server
- Opens the dbt documentation site

## 7.9 dbt workflow

### 7.9.1 Typical workflow
`dbt deps -> dbt seed  -> dbt run  -> (dbt test  ->) dbt build`

### 7.9.2 Selective runs
`dbt run --select stg_orders`

## 7.10 Summary
|      Command      |      Purpose     |
|:-----------------:|:----------------:|
| dbt run           | Build models     |
| dbt test          | Run tests        |
| dbt build         | Full pipeline    |
| dbt seed          | Load CSV seeds   |
| dbt snapshot      | Track history    |
| dbt deps          | Install packages |
| dbt docs generate | Build docs       |
| dbt docs serve    | View docs        |





















